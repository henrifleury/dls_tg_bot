{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RxDNzVslAgQ9"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a906a59b7744fe3b73366fb9593785d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c0a7a87c4a348b7b51ccd05960d2d85",
              "IPY_MODEL_6b07fabf3b3d4f14946cfb61d82d7295",
              "IPY_MODEL_cf5dc86719014ae8acff66da4ccfd499"
            ],
            "layout": "IPY_MODEL_c028948061944fb2a739d04fdb533ee7"
          }
        },
        "8c0a7a87c4a348b7b51ccd05960d2d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911db30e367a4aa0947d4e5cac06c070",
            "placeholder": "​",
            "style": "IPY_MODEL_5ad8abca41994c5c9552c72af0d0d04a",
            "value": "RealESRGAN_x4.pth: 100%"
          }
        },
        "6b07fabf3b3d4f14946cfb61d82d7295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_434a57c8ce104963a67c36da0dafb000",
            "max": 67040989,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a797316bbbb4bc493a966c00591c644",
            "value": 67040989
          }
        },
        "cf5dc86719014ae8acff66da4ccfd499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abb95ca3cb6d4a999518da1499a53ef0",
            "placeholder": "​",
            "style": "IPY_MODEL_1576714412ce46649b6d66fa30b7829d",
            "value": " 67.0M/67.0M [00:00&lt;00:00, 91.9MB/s]"
          }
        },
        "c028948061944fb2a739d04fdb533ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "911db30e367a4aa0947d4e5cac06c070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad8abca41994c5c9552c72af0d0d04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "434a57c8ce104963a67c36da0dafb000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a797316bbbb4bc493a966c00591c644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abb95ca3cb6d4a999518da1499a53ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1576714412ce46649b6d66fa30b7829d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# turn on gpu or prepare to wait, CPU inference is VERY slow"
      ],
      "metadata": {
        "id": "_qqWoj6BTO3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LICENSE\n"
      ],
      "metadata": {
        "id": "w0qRru0O_Vjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Real-ESRGAN-Sber model used by\n",
        "\n",
        "BSD 3-Clause License\n",
        "\n",
        "https://github.com/ai-forever/Real-ESRGAN\n",
        "\n",
        "https://colab.research.google.com/drive/1YlWt--P9w25JUs8bHBOuf8GcMkx-hocP?usp=sharing\n",
        "\n",
        "\n",
        "Copyright (c) 2021, Sberbank AI\n",
        "All rights reserved.\n",
        "\n",
        "Redistribution and use in source and binary forms, with or without\n",
        "modification, are permitted provided that the following conditions are met:\n",
        "\n",
        "1. Redistributions of source code must retain the above copyright notice, this\n",
        "   list of conditions and the following disclaimer.\n",
        "\n",
        "2. Redistributions in binary form must reproduce the above copyright notice,\n",
        "   this list of conditions and the following disclaimer in the documentation\n",
        "   and/or other materials provided with the distribution.\n",
        "\n",
        "3. Neither the name of the copyright holder nor the names of its\n",
        "   contributors may be used to endorse or promote products derived from\n",
        "   this software without specific prior written permission.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
        "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
        "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
        "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
        "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
        "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
        "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
        "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
        "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
        "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
      ],
      "metadata": {
        "id": "1m6uMXHm9quh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is a demo notebook for educational purpose only"
      ],
      "metadata": {
        "id": "VApeMWzh_lyr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czlr7j7-t1Fw"
      },
      "source": [
        "\n",
        "\n",
        "# Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXm_whLxt-2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8962486d-8d1f-4bb8-cc81-d88857153466"
      },
      "source": [
        "!pip install git+https://github.com/sberbank-ai/Real-ESRGAN.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/sberbank-ai/Real-ESRGAN.git\n",
            "  Cloning https://github.com/sberbank-ai/Real-ESRGAN.git to /tmp/pip-req-build-1letfkjz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/sberbank-ai/Real-ESRGAN.git /tmp/pip-req-build-1letfkjz\n",
            "  Resolved https://github.com/sberbank-ai/Real-ESRGAN.git to commit 362a0316878f41dbdfbb23657b450c3353de5acf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from RealESRGAN==1.0) (1.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from RealESRGAN==1.0) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from RealESRGAN==1.0) (9.4.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from RealESRGAN==1.0) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from RealESRGAN==1.0) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from RealESRGAN==1.0) (4.66.4)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from RealESRGAN==1.0) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->RealESRGAN==1.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->RealESRGAN==1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->RealESRGAN==1.0) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->RealESRGAN==1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->RealESRGAN==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->RealESRGAN==1.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7->RealESRGAN==1.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->RealESRGAN==1.0) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->RealESRGAN==1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->RealESRGAN==1.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->RealESRGAN==1.0) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->RealESRGAN==1.0) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->RealESRGAN==1.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->RealESRGAN==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->RealESRGAN==1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->RealESRGAN==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->RealESRGAN==1.0) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->RealESRGAN==1.0) (1.3.0)\n",
            "Building wheels for collected packages: RealESRGAN\n",
            "  Building wheel for RealESRGAN (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for RealESRGAN: filename=RealESRGAN-1.0-py3-none-any.whl size=9106 sha256=fd340af1c1bd6ae8dc630a37372715fba298072777c43716bd3fa3f32d556dfe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cgoc6zv1/wheels/dd/a3/7d/774508ed192455403be294c8a6c4ad1c83dde8fcdd8903e64a\n",
            "Successfully built RealESRGAN\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, RealESRGAN\n",
            "Successfully installed RealESRGAN-1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## !pip install -r requirements.txt don't work\n"
      ],
      "metadata": {
        "id": "RxDNzVslAgQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install don't work properly\n",
        "with open('requirements.txt', 'w') as f:\n",
        "    f.write('''aiofiles==23.2.1\n",
        "    aiogram==3.8.0\n",
        "    aiohttp==3.9.5\n",
        "    aiohttp-session==2.12.0\n",
        "    aiosignal==1.3.1\n",
        "    annotated-types==0.7.0\n",
        "    apispec==6.0.2\n",
        "    apturl==0.5.2\n",
        "    async-timeout==4.0.2\n",
        "    asyncpg==0.27.0\n",
        "    attrs==22.2.0\n",
        "    bcrypt==3.2.0\n",
        "    black==24.4.2\n",
        "    blinker==1.4\n",
        "    Brlapi==0.8.3\n",
        "    certifi==2024.6.2\n",
        "    cfgv==3.4.0\n",
        "    chardet==4.0.0\n",
        "    charset-normalizer==3.0.1\n",
        "    click==8.0.3\n",
        "    colorama==0.4.4\n",
        "    command-not-found==0.3\n",
        "    cryptography==3.4.8\n",
        "    cupshelpers==1.0\n",
        "    dbus-python==1.2.18\n",
        "    defer==1.0.6\n",
        "    distlib==0.3.8\n",
        "    distro==1.7.0\n",
        "    distro-info===1.1build1\n",
        "    duplicity==0.8.21\n",
        "    environs==11.0.0\n",
        "    fasteners==0.14.1\n",
        "    filelock==3.15.4\n",
        "    flake8==7.1.0\n",
        "    frozenlist==1.3.3\n",
        "    fsspec==2024.6.1\n",
        "    future==0.18.2\n",
        "    httplib2==0.20.2\n",
        "    huggingface-hub==0.23.4\n",
        "    identify==2.6.0\n",
        "    idna==3.3\n",
        "    importlib-metadata==4.6.4\n",
        "    iniconfig==2.0.0\n",
        "    jeepney==0.7.1\n",
        "    Jinja2==3.1.2\n",
        "    keyring==23.5.0\n",
        "    language-selector==0.1\n",
        "    launchpadlib==1.10.16\n",
        "    lazr.restfulclient==0.14.4\n",
        "    lazr.uri==1.0.6\n",
        "    lockfile==0.12.2\n",
        "    louis==3.20.0\n",
        "    macaroonbakery==1.3.1\n",
        "    magic-filter==1.0.12\n",
        "    Mako==1.1.3\n",
        "    MarkupSafe==2.0.1\n",
        "    marshmallow==3.19.0\n",
        "    mccabe==0.7.0\n",
        "    monotonic==1.6\n",
        "    more-itertools==8.10.0\n",
        "    mpmath==1.3.0\n",
        "    multidict==6.0.4\n",
        "    mypy-extensions==1.0.0\n",
        "    netifaces==0.11.0\n",
        "    networkx==3.3\n",
        "    nodeenv==1.9.1\n",
        "    numpy==2.0.0\n",
        "    nvidia-cublas-cu12==12.1.3.1\n",
        "    nvidia-cuda-cupti-cu12==12.1.105\n",
        "    nvidia-cuda-nvrtc-cu12==12.1.105\n",
        "    nvidia-cuda-runtime-cu12==12.1.105\n",
        "    nvidia-cudnn-cu12==8.9.2.26\n",
        "    nvidia-cufft-cu12==11.0.2.54\n",
        "    nvidia-curand-cu12==10.3.2.106\n",
        "    cryptography==3.4.8\n",
        "    nvidia-cusolver-cu12==11.4.5.107\n",
        "    nvidia-cusparse-cu12==12.1.0.106\n",
        "    nvidia-nccl-cu12==2.20.5\n",
        "    nvidia-nvjitlink-cu12==12.5.82\n",
        "    nvidia-nvtx-cu12==12.1.105\n",
        "    oauthlib==3.2.0\n",
        "    olefile==0.46\n",
        "    opencv-python==4.10.0.84\n",
        "    packaging==23.0\n",
        "    paramiko==2.9.3\n",
        "    pathspec==0.12.1\n",
        "    pexpect==4.8.0\n",
        "    pillow==10.4.0\n",
        "    platformdirs==4.2.2\n",
        "    pluggy==1.5.0\n",
        "    pre-commit==3.7.1\n",
        "    protobuf==3.12.4\n",
        "    ptyprocess==0.7.0\n",
        "    pycairo==1.20.1\n",
        "    pycodestyle==2.12.0\n",
        "    pycups==2.0.1\n",
        "    pydantic==2.7.4\n",
        "    pydantic_core==2.18.4\n",
        "    pyflakes==3.2.0\n",
        "    PyGObject==3.42.1\n",
        "    PyJWT==2.3.0\n",
        "    pymacaroons==0.13.0\n",
        "    PyNaCl==1.5.0\n",
        "    pyparsing==2.4.7\n",
        "    pyRFC3339==1.1\n",
        "    pytest==8.2.2\n",
        "    python-apt==2.4.0+ubuntu1\n",
        "    python-dateutil==2.8.1\n",
        "    python-debian===0.1.43ubuntu1\n",
        "    python-dotenv==1.0.1\n",
        "    pytz==2022.1\n",
        "    pyxdg==0.27\n",
        "    PyYAML==5.4.1\n",
        "    RealESRGAN @ git+https://github.com/sberbank-ai/Real-ESRGAN.git@362a0316878f41dbdfbb23657b450c3353de5acf\n",
        "    reportlab==3.6.8\n",
        "    requests==2.25.1\n",
        "    SecretStorage==3.3.1\n",
        "    six==1.16.0\n",
        "    sympy==1.13.0\n",
        "    systemd-python==234\n",
        "    torch==2.3.1\n",
        "    torchvision==0.18.1\n",
        "    tqdm==4.66.4\n",
        "    triton==2.3.1\n",
        "    typing_extensions==4.12.2\n",
        "    ubuntu-advantage-tools==8001\n",
        "    ubuntu-drivers-common==0.0.0\n",
        "    ufw==0.36.1\n",
        "    unattended-upgrades==0.1\n",
        "    cryptography==3.4.8\n",
        "    urllib3==1.26.5\n",
        "    usb-creator==0.3.7\n",
        "    virtualenv==20.26.3\n",
        "    wadllib==1.3.6\n",
        "    webargs==8.2.0\n",
        "    xdg==5\n",
        "    xkit==0.0.0\n",
        "    yarl==1.8.2\n",
        "    zipp==1.0.0'''\n",
        "    )\n",
        "# error !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "3S2xU1fk4BPE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## manual package installation"
      ],
      "metadata": {
        "id": "K7qL-q9tAvAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiogram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py1mLpmI73q1",
        "outputId": "669288e8-f188-463d-98fa-c81ccf5809f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiogram\n",
            "  Downloading aiogram-3.10.0-py3-none-any.whl (570 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/570.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/570.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.6/570.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles~=23.2.1 (from aiogram)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: aiohttp~=3.9.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (3.9.5)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2024.7.4)\n",
            "Collecting magic-filter<1.1,>=1.0.12 (from aiogram)\n",
            "  Downloading magic_filter-1.0.12-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pydantic<2.9,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions<=5.0,>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.9,>=2.4.1->aiogram) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.9,>=2.4.1->aiogram) (2.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp~=3.9.0->aiogram) (3.7)\n",
            "Installing collected packages: magic-filter, aiofiles, aiogram\n",
            "Successfully installed aiofiles-23.2.1 aiogram-3.10.0 magic-filter-1.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install environs\n",
        "with open('/content/.env', 'w') as f:\n",
        "    f.write('''BOT_TOKEN = XXXX\n",
        "    ADMIN_ID = YYYY\n",
        "    '''\n",
        "    )\n",
        "!ls\n",
        "# .env save don't work too"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JAnQo288NH-",
        "outputId": "fcc71ee4-9407-42d9-bed2-37a3026f2920"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "BOT_TOKEN = userdata.get('YK_TOKEN')\n",
        "None"
      ],
      "metadata": {
        "id": "zTzqCQOfBvAa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qa4O08u8u9n",
        "outputId": "b18a6a49-4d6d-42bf-c105-ac2f4285d3aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TG_BOT"
      ],
      "metadata": {
        "id": "LrxK5SPKsS38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import asyncio\n",
        "\n",
        "# from environs import Env\n",
        "from aiogram import Bot, Dispatcher\n",
        "from aiogram.filters import Command\n",
        "from aiogram.types import Message\n",
        "\n",
        "from aiogram.types import ContentType\n",
        "from aiogram import F\n",
        "from time import time\n",
        "\n",
        "# from config import UPLOAD_FOLDER, LOG_LEVEL\n",
        "# from resolutor import main as resolutor\n",
        "# from sender import main as sender\n",
        "from threading import Thread\n",
        "from aiofiles.os import listdir\n",
        "\n",
        "#@title Config\n",
        "\n",
        "\n",
        "#cwd = os.path.abspath(os.path.dirname(__file__))\n",
        "cwd = '/content'\n",
        "UPLOAD_FOLDER = os.path.join(cwd, 'inputs')\n",
        "RESULT_FOLDER = os.path.join(cwd, 'results')\n",
        "API_URL = 'https://api.telegram.org/bot'\n",
        "LOG_LEVEL = 'INFO'\n",
        "\n",
        "SENDER_MAX_N_THREADS = 3\n",
        "SENDER_DELAY = 3\n",
        "\n",
        "!mkdir {UPLOAD_FOLDER}\n",
        "!mkdir {RESULT_FOLDER}\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "PGgICGomC96a",
        "outputId": "a5e8e832-ff61-4bdd-f13c-f390f82a9172"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\tresults  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import logging\n",
        "import requests\n",
        "\n",
        "from asyncio import Semaphore\n",
        "from aiofiles.os import remove, listdir\n",
        "#from environs import Env\n",
        "#from config import RESULT_FOLDER, API_URL, LOG_LEVEL\n",
        "#from config import SENDER_MAX_N_THREADS as MAX_N_THREADS\n",
        "#from config import SENDER_DELAY as DELAY\n",
        "\n",
        "#@title Sender\n",
        "\n",
        "MAX_N_THREADS = SENDER_MAX_N_THREADS\n",
        "DELAY = SENDER_DELAY\n",
        "\n",
        "\n",
        "logging.basicConfig(level=LOG_LEVEL)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "#env = Env()\n",
        "#env.read_env()\n",
        "\n",
        "#BOT_TOKEN = env(\"BOT_TOKEN\")\n",
        "\n",
        "\n",
        "async def task_wrapper(semaphore: Semaphore, f_path, *args):\n",
        "    await semaphore.acquire()\n",
        "    try:\n",
        "        f_name = f_path.split(os.sep)[-1]\n",
        "        (_, message_id, chat_id) = f_name.split(\"_\")[:3]\n",
        "\n",
        "        # TODO check file size and raise exception if > 10Mb\n",
        "        #  (tg limit 10Mb - will not be send)\n",
        "\n",
        "        data = {\"chat_id\": chat_id, \"caption\": \"enhanced photo\"}\n",
        "        url = f\"{API_URL}{BOT_TOKEN}/sendPhoto?chat_id={chat_id}\"\n",
        "        with open(f_path, \"rb\") as img_f:\n",
        "            # res =\n",
        "            requests.post(url, data=data, files={\"photo\": img_f})\n",
        "        # TODO check res.json() and raise exception if something wrong\n",
        "        logger.info(\n",
        "            f\"{f_name} send to chat: {chat_id}, \" f\"as reply to message: {message_id}\"\n",
        "        )\n",
        "        await remove(f_path)\n",
        "        logger.info(f\"{f_path} deleted\")\n",
        "    except Exception as ex:\n",
        "        logger.error(f\"exc: {ex}\")\n",
        "        if os.path.isfile(f_path):\n",
        "            await remove(f_path)\n",
        "            logger.error(f\"{f_path} deleted by exception\")\n",
        "            semaphore.release()\n",
        "    finally:\n",
        "        semaphore.release()\n",
        "\n",
        "\n",
        "async def sender(\n",
        "    img_dir=RESULT_FOLDER,\n",
        "    max_n_threads=MAX_N_THREADS,\n",
        "    wrapper=task_wrapper,\n",
        "    delay=DELAY,\n",
        "):\n",
        "    logger.info(f\"{__name__} startung\")\n",
        "    semaphore = Semaphore(max_n_threads)\n",
        "    while True:\n",
        "        img_list = sorted(await listdir(img_dir))\n",
        "        if len(img_list) == 0:\n",
        "            await asyncio.sleep(delay)\n",
        "            continue\n",
        "        threads_nbr = min(MAX_N_THREADS, len(img_list))\n",
        "        tasks = []\n",
        "        logger.info(\n",
        "            f\"start processing list: {img_list[:threads_nbr]}, \"\n",
        "            f\"{len(img_list)} images in queue\"\n",
        "        )\n",
        "        for f_name in img_list[:threads_nbr]:\n",
        "            f_path = os.path.join(img_dir, f_name)\n",
        "            task = asyncio.create_task(wrapper(semaphore, f_path))\n",
        "            tasks.append(task)\n",
        "\n",
        "        await asyncio.gather(*tasks)\n",
        "        logger.info(f\"finish processing list: {img_list[:threads_nbr]}\")\n",
        "\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "    # asyncio.run(main())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d5Z4pySSD1Iv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from RealESRGAN import RealESRGAN\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import asyncio\n",
        "\n",
        "#@title Upload and upscale images or .tar archives - it is sber AI code\n",
        "import os\n",
        "# from google.colab import files\n",
        "# import shutil\n",
        "from io import BytesIO\n",
        "import io\n",
        "import tarfile\n",
        "\n",
        "#from config import UPLOAD_FOLDER, RESULT_FOLDER\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device:', device)\n",
        "\n",
        "model_scale = \"4\"\n",
        "\n",
        "model = RealESRGAN(device, scale=int(model_scale))\n",
        "model.load_weights(f'weights/RealESRGAN_x{model_scale}.pth')\n",
        "\n",
        "#os.makedirs(upload_folder, exist_ok=True)\n",
        "#os.makedirs(result_folder, exist_ok=True)\n",
        "\n",
        "IMAGE_FORMATS = ('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')\n",
        "\n",
        "def image_to_tar_format(img, image_name):\n",
        "    buff = BytesIO()\n",
        "    if '.png' in image_name.lower():\n",
        "        img = img.convert('RGBA')\n",
        "        img.save(buff, format='PNG')\n",
        "    else:\n",
        "        img.save(buff, format='JPEG')\n",
        "    buff.seek(0)\n",
        "    fp = io.BufferedReader(buff)\n",
        "    img_tar_info = tarfile.TarInfo(name=image_name)\n",
        "    img_tar_info.size = len(buff.getvalue())\n",
        "    return img_tar_info, fp\n",
        "\n",
        "def process_tar(path_to_tar):\n",
        "    processing_tar = tarfile.open(path_to_tar, mode='r')\n",
        "    result_tar_path = os.path.join('../results/', os.path.basename(path_to_tar))\n",
        "    save_tar = tarfile.open(result_tar_path, 'w')\n",
        "\n",
        "    for c, member in enumerate(processing_tar):\n",
        "        print(f'{c}, processing {member.name}')\n",
        "\n",
        "        if not member.name.endswith(IMAGE_FORMATS):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            img_bytes = BytesIO(processing_tar.extractfile(member.name).read())\n",
        "            img_lr = Image.open(img_bytes, mode='r').convert('RGB')\n",
        "        except Exception as err:\n",
        "            print(f'Unable to open file {member.name}, skipping')\n",
        "            continue\n",
        "\n",
        "        img_sr = model.predict(np.array(img_lr))\n",
        "        # adding to save_tar\n",
        "        img_tar_info, fp = image_to_tar_format(img_sr, member.name)\n",
        "        save_tar.addfile(img_tar_info, fp)\n",
        "\n",
        "    processing_tar.close()\n",
        "    save_tar.close()\n",
        "    print(f'Finished! Archive saved to {result_tar_path}')\n",
        "\n",
        "def process_input(filename):\n",
        "    # if tarfile.is_tarfile(filename):\n",
        "        # process_tar(filename)\n",
        "    # else:\n",
        "    result_image_path = os.path.join(RESULT_FOLDER,os.path.basename(filename))\n",
        "    image = Image.open(filename).convert('RGB')\n",
        "    sr_image = model.predict(np.array(image))\n",
        "    sr_image.save(result_image_path)\n",
        "    print(f'Finished! Image saved to {result_image_path}')\n",
        "    return result_image_path\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "1a906a59b7744fe3b73366fb9593785d",
            "8c0a7a87c4a348b7b51ccd05960d2d85",
            "6b07fabf3b3d4f14946cfb61d82d7295",
            "cf5dc86719014ae8acff66da4ccfd499",
            "c028948061944fb2a739d04fdb533ee7",
            "911db30e367a4aa0947d4e5cac06c070",
            "5ad8abca41994c5c9552c72af0d0d04a",
            "434a57c8ce104963a67c36da0dafb000",
            "1a797316bbbb4bc493a966c00591c644",
            "abb95ca3cb6d4a999518da1499a53ef0",
            "1576714412ce46649b6d66fa30b7829d"
          ]
        },
        "cellView": "form",
        "id": "EykG2ZveExr0",
        "outputId": "5072fc50-0ba3-46a6-b1a9-00db2b89b148"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:671: FutureWarning: 'cached_download' is the legacy way to download files from the HF hub, please consider upgrading to 'hf_hub_download'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RealESRGAN_x4.pth:   0%|          | 0.00/67.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a906a59b7744fe3b73366fb9593785d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights downloaded to: weights/RealESRGAN_x4.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from asyncio import Semaphore\n",
        "import logging\n",
        "#from models.Real_ESRGAN import process_input\n",
        "from aiofiles.os import remove, listdir\n",
        "\n",
        "# from config import UPLOAD_FOLDER, LOG_LEVEL  # RESULT_FOLDER,\n",
        "\n",
        "#@title Resolutor\n",
        "\n",
        "\n",
        "logging.basicConfig(level=LOG_LEVEL)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MAX_N_THREADS = 3\n",
        "DELAY = 1\n",
        "\n",
        "\n",
        "async def task_wrapper(semaphore: Semaphore, f_path, *args):\n",
        "    await semaphore.acquire()\n",
        "    try:\n",
        "        # new_f_path = await async_process_input(f_path)\n",
        "        new_f_path = process_input(f_path)\n",
        "        # TODO check file size and raise exception if > 10Mb/4\n",
        "        # TODO (tg limit 10Mb - will not be send)\n",
        "        logger.info(f'{f_path} processed to {new_f_path}')\n",
        "        await remove(f_path)\n",
        "        logger.info(f'{f_path} deleted')\n",
        "    except Exception as ex:\n",
        "        logger.info(f'exc: {ex}')\n",
        "        pass\n",
        "    finally:\n",
        "        semaphore.release()\n",
        "\n",
        "\n",
        "async def resolutor():\n",
        "    logger.info('resolutor starting')\n",
        "    semaphore = Semaphore(MAX_N_THREADS)\n",
        "    while True:\n",
        "        img_list = sorted(await listdir(UPLOAD_FOLDER))\n",
        "        if len(img_list) == 0:\n",
        "            await asyncio.sleep(DELAY)\n",
        "            continue\n",
        "        max_threads_nbr = min(MAX_N_THREADS, len(img_list))\n",
        "        tasks = []\n",
        "        logger.info(f'start processing list: {img_list[:max_threads_nbr]},'\n",
        "                    f' {len(img_list)} images in queue')\n",
        "        for f_name in img_list[:max_threads_nbr]:\n",
        "            f_path = os.path.join(UPLOAD_FOLDER, f_name)\n",
        "            task = asyncio.create_task(task_wrapper(semaphore, f_path))\n",
        "            tasks.append(task)\n",
        "\n",
        "        await asyncio.gather(*tasks)\n",
        "        logger.info(f'finish processing list: {img_list[:max_threads_nbr]}')\n"
      ],
      "metadata": {
        "id": "ydlzUSAPEd_F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# asyncio don't work properli in colab\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "# import os\n",
        "import logging\n",
        "import asyncio\n",
        "\n",
        "# from environs import Env\n",
        "from aiogram import Bot, Dispatcher\n",
        "from aiogram.filters import Command\n",
        "from aiogram.types import Message\n",
        "\n",
        "from aiogram.types import ContentType\n",
        "from aiogram import F\n",
        "from time import time\n",
        "\n",
        "# from config import UPLOAD_FOLDER, LOG_LEVEL\n",
        "# from resolutor import main as resolutor\n",
        "# from sender import main as sender\n",
        "from threading import Thread\n",
        "from aiofiles.os import listdir\n",
        "\n",
        "\n",
        "logging.basicConfig(level=LOG_LEVEL)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "#@title Poller\n",
        "\n",
        "'''\n",
        "env = Env()\n",
        "env.read_env()\n",
        "\n",
        "\n",
        "BOT_TOKEN = env('BOT_TOKEN')\n",
        "'''\n",
        "\n",
        "bot = Bot(token=BOT_TOKEN)\n",
        "dp = Dispatcher()\n",
        "\n",
        "\n",
        "@dp.message(Command(commands=[\"start\"]))\n",
        "async def process_start_command(message: Message):\n",
        "    await message.answer(\n",
        "        'Привет, это бот-улучшатель изображений. Пришли картинку и я попробую/'\n",
        "        ' в 2 раза увеличить ее разрешение')\n",
        "\n",
        "\n",
        "@dp.message(Command(commands=[\"help\"]))\n",
        "async def process_help_command(message: Message):\n",
        "    await message.answer('Пришли картинку и я попробую в 2 раза увеличить ее/'\n",
        "                         ' разрешение')\n",
        "\n",
        "\n",
        "@dp.message(F.content_type == ContentType.PHOTO)\n",
        "async def process_photo(message: Message):\n",
        "    f_path = f\"{UPLOAD_FOLDER}/{time()}_{message.message_id}\"\n",
        "    f_path += f\"_{message.chat.id}_{message.photo[-1].file_id}.jpg\"\n",
        "    await bot.download(file=message.photo[-1].file_id, destination=f_path)\n",
        "    img_list = await listdir(UPLOAD_FOLDER)\n",
        "    q_len = len(img_list)\n",
        "    if q_len > 1:\n",
        "        await message.answer(f'Ждите ответа, в очереди на увеличение'\n",
        "                             f' разрешения {q_len} файла(ов)')\n",
        "\n",
        "    logger.info(f'{f_path} получен')\n",
        "\n",
        "\n",
        "@dp.message()\n",
        "async def process_other_messages(message: Message):\n",
        "    await message.reply('Жду картинку в низком разрешении')\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#async def main():\n",
        "\n",
        "    # TODO all threads safe termination\n",
        "Thread(target=asyncio.run, args=(sender(),)).start()\n",
        "Thread(target=asyncio.run, args=(resolutor(),)).start()\n",
        "dp.run_polling(bot)\n",
        "#Thread(target=asyncio.run, args=(dp.run_polling(bot),)).start()\n",
        "'''\n",
        "loop = asyncio.get_running_loop()\n",
        "#await loop.create_task(main())\n",
        "#dp.run_polling(bot)\n",
        "await loop.create_task(dp.run_polling(bot))'''"
      ],
      "metadata": {
        "id": "bhdrn9oVFTgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c3bf12-17e8-4d19-905f-baf6abf355aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished! Image saved to /content/results/1720895034.9290261_89_903775208_AgACAgIAAxkBAANZZpLGOk_FmyQWK1DE_3bmVd2MH34AAt7fMRvKJJhIa0OnaD2S2GgBAAMCAANtAAM1BA.jpg\n"
          ]
        }
      ]
    }
  ]
}